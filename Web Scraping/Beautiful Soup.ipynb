{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup is a web Scraping tool, Basically it takes the HTML structure of a web page. Then we parse that HTML and get whatever we want from that webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html><head><title>Learning Beautiful Soup</title></head><body><h1> About Us </h1><div class=\"first_div\"><p>Coding Ninjas Website</p><a href=\"https://www.codingninjas.in/\">Link to Coding Ninjas Website</a><ul><li>This</li><li>is</li><li>an</li><li>unordered</li><li>list.</li></ul></div><p id=\"template_p\">This is a template paragraph tag</p><a href=\"https://www.facebook.com/codingninjas/\">This is the link of our Facebook Page</a></body></html>\n",
      "\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Learning Beautiful Soup\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   About Us\n",
      "  </h1>\n",
      "  <div class=\"first_div\">\n",
      "   <p>\n",
      "    Coding Ninjas Website\n",
      "   </p>\n",
      "   <a href=\"https://www.codingninjas.in/\">\n",
      "    Link to Coding Ninjas Website\n",
      "   </a>\n",
      "   <ul>\n",
      "    <li>\n",
      "     This\n",
      "    </li>\n",
      "    <li>\n",
      "     is\n",
      "    </li>\n",
      "    <li>\n",
      "     an\n",
      "    </li>\n",
      "    <li>\n",
      "     unordered\n",
      "    </li>\n",
      "    <li>\n",
      "     list.\n",
      "    </li>\n",
      "   </ul>\n",
      "  </div>\n",
      "  <p id=\"template_p\">\n",
      "   This is a template paragraph tag\n",
      "  </p>\n",
      "  <a href=\"https://www.facebook.com/codingninjas/\">\n",
      "   This is the link of our Facebook Page\n",
      "  </a>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Right now we haven't scrapped anything, this is a random HTML document which we get when we scrap\n",
    "html = '<!DOCTYPE html><html><head><title>Learning Beautiful Soup</title></head>\\\n",
    "<body><h1> About Us </h1><div class = \"first_div\"><p>Coding Ninjas Website</p>\\\n",
    "<a href=\"https://www.codingninjas.in/\">Link to Coding Ninjas Website</a>\\\n",
    "<ul><li>This</li><li>is</li><li>an</li><li>unordered</li><li>list.</li></ul>\\\n",
    "</div><p id = \"template_p\">This is a template paragraph tag</p>\\\n",
    "<a href = \"https://www.facebook.com/codingninjas/\">\\\n",
    "This is the link of our Facebook Page</a></body></html>'\n",
    "\n",
    "data = BeautifulSoup(html,'html.parser')\n",
    "print(data)\n",
    "print()\n",
    "print(data.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Access Title, head and paragrpahs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Learning Beautiful Soup</title>\n",
      "\n",
      "<head><title>Learning Beautiful Soup</title></head>\n",
      "\n",
      "<h1> About Us </h1>\n",
      "\n",
      "<p>Coding Ninjas Website</p>\n"
     ]
    }
   ],
   "source": [
    "print(data.title)\n",
    "print()\n",
    "print(data.head)\n",
    "print()\n",
    "print(data.h1)\n",
    "print()\n",
    "# when you do data,p, it shows only 1st para\n",
    "print(data.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Access elements and text in Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Learning Beautiful Soup</title>\n",
      "title\n",
      "Learning Beautiful Soup\n",
      "\n",
      "Coding Ninjas Website\n",
      "Link to Coding Ninjas Website\n",
      "None\n",
      "\n",
      "<p>Coding Ninjas Website</p>\n",
      "\n",
      "2\n",
      "\n",
      "26\n",
      "\n",
      "{'class': ['first_div']}\n",
      "['first_div']\n"
     ]
    }
   ],
   "source": [
    "print(data.title)\n",
    "print(data.title.name)\n",
    "print(data.title.string) # note this works when there is only 1 tag in between that tag\n",
    "print()\n",
    "\n",
    "lal = data.find('div')  # for multpile tags use this // actually have to use i.strings //\"s\" at the end of 'strings'\n",
    "for i in lal :          # i.stripped_string - to remove trailing zeros\n",
    "    print(i.string)\n",
    "################################# to go within Tags\n",
    "print()\n",
    "print(data.div.p)\n",
    "print()\n",
    "\n",
    "# if you want to see how many sub-tags does a tag have\n",
    "li = data.html.contents\n",
    "print(len(li))\n",
    "print()\n",
    "\n",
    "li2 = list(data.html.descendants)\n",
    "print(len(li2))\n",
    "print()\n",
    "# various other tags also presnt - parent,parents,children,next_element,previous_emelent,next_sibling,next_siblings\n",
    "\n",
    "# We can also get attributes in a tag - in the form of a dictionary\n",
    "print(data.div.attrs)\n",
    "# Can access sttribute string as well\n",
    "print(data.div['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) To get all the text at once in an entire Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Beautiful Soup About Us Coding Ninjas WebsiteLink to Coding Ninjas WebsiteThisisanunorderedlist.This is a template paragraph tagThis is the link of our Facebook Page\n"
     ]
    }
   ],
   "source": [
    "print(data.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) To find particular things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Coding Ninjas Website</p>\n",
      "[<p>Coding Ninjas Website</p>, <p id=\"template_p\">This is a template paragraph tag</p>]\n",
      "[]\n",
      "[<div class=\"first_div\"><p>Coding Ninjas Website</p><a href=\"https://www.codingninjas.in/\">Link to Coding Ninjas Website</a><ul><li>This</li><li>is</li><li>an</li><li>unordered</li><li>list.</li></ul></div>]\n"
     ]
    }
   ],
   "source": [
    "print(data.find('p'))\n",
    "\n",
    "# The following finds all paras\n",
    "print(data.find_all('p'))\n",
    "# Can find particular ID's as well\n",
    "print(data.find_all(id = 'first_div'))\n",
    "print(data.find_all(class_ = 'first_div'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) TO properly Scrape a website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>\n",
      "    All products | Books to Scrape - Sandbox\n",
      "</title>\n",
      "\n",
      "    All products | Books to Scrape - Sandbox\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "response = requests.get('http://books.toscrape.com/')\n",
    "\n",
    "html_data = response.text\n",
    "data = BeautifulSoup(html_data,'html.parser')\n",
    "\n",
    "#Extract whatever we want know\n",
    "\n",
    "print(data.title)\n",
    "print(data.title.string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
